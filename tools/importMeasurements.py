import os
import glob
import pandas as pd
import psycopg2
from psycopg2 import extras
# ç¡®ä¿ config.py èƒ½å¤Ÿè¢«å¯¼å…¥
import config
from datetime import datetime  # å¯¼å…¥ datetime åº“ç”¨äºæ—¥æœŸå¤„ç†

# ================= é…ç½®éƒ¨åˆ† =================
# æŒ‡å®šå­˜æ”¾ CSV æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤å½“å‰ç›®å½•)
CSV_FOLDER_PATH = r'../database/test/' #è¿™é‡Œæ˜¯csvæ•°æ®çš„ç›®å½•


# ===========================================

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(
            host=config.DB_HOST,
            port=config.DB_PORT,
            dbname=config.DB_NAME,
            user=config.DB_USER,
            password=config.DB_PASSWORD
        )
        return conn
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None


def load_id_mappings(cursor):
    """
    ä¸ºäº†æé«˜æ€§èƒ½ï¼Œå…ˆå°†æ•°æ®åº“ä¸­çš„ site_name å’Œ pollutant_name
    æ˜ å°„ä¸ºå¯¹åº”çš„ IDï¼Œå­˜å…¥å­—å…¸ä¸­ï¼Œé¿å…æ¯æ’å…¥ä¸€è¡Œéƒ½å»æŸ¥è¯¢ IDã€‚
    """
    # è·å–ç«™ç‚¹æ˜ å°„: { 'ä¸œåŸä¸œå››': 1, ... }
    cursor.execute("SELECT site_name, site_id FROM sites")
    site_map = dict(cursor.fetchall())

    # è·å–æ±¡æŸ“ç‰©æ˜ å°„: { 'NO2': 1, ... }
    cursor.execute("SELECT pollutant_name, pollutant_id FROM pollutants")
    pollutant_map = dict(cursor.fetchall())

    return site_map, pollutant_map


def generate_distinct_id(date_str, hour, site_id, pollutant_id):
    """
    æ ¹æ®è§„åˆ™ç”Ÿæˆå”¯ä¸€çš„ distinct_id:
    "date-hour(ä¸¤ä½æ•´æ•°)-site_id-pollute_id"
    ä¾‹å¦‚: 2024-02-10-00281
    """
    # hour_val æ˜¯æ•´æ•°ï¼Œzfill(2) å®ç°äº†ä¸è¶³ä¸¤ä½è¡¥0
    hour_str = str(hour).zfill(2)

    # æ ¼å¼åŒ–å¹¶ç»„åˆ
    return f"{date_str}-{hour_str}{site_id}{pollutant_id}"


def process_csv_and_insert(file_path, cursor, site_map, pollutant_map):
    print(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path} ...")

    try:
        # 1. è¯»å– CSV
        df = pd.read_csv(file_path)

        # 2. æ•°æ®è½¬æ¢ (Wide to Long)
        id_vars = ['data', 'hour', 'type']
        value_vars = [col for col in df.columns if col not in id_vars]

        melted_df = df.melt(
            id_vars=id_vars,
            value_vars=value_vars,
            var_name='site_name',
            value_name='value'
        )

        # 3. æ•°æ®æ¸…æ´—
        melted_df = melted_df.dropna(subset=['value'])

        # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®åˆ—è¡¨
        records_to_insert = []

        for _, row in melted_df.iterrows():
            date_val = row['data']  # CSV header æ˜¯ data (ä¾‹å¦‚: '2024-01-01')
            hour_val = row['hour']
            pollutant_name = row['type']
            site_name = row['site_name']
            value = row['value']

            # è·å– ID
            site_id = site_map.get(site_name)
            pollutant_id = pollutant_map.get(pollutant_name)

            # æ£€æŸ¥ç«™ç‚¹æˆ–æ±¡æŸ“ç‰©æ˜¯å¦å­˜åœ¨äºæ•°æ®åº“ä¸­
            if site_id is None:
                continue
            if pollutant_id is None:
                print(f"âš ï¸ è­¦å‘Š: æ±¡æŸ“ç‰© '{pollutant_name}' åœ¨æ•°æ®åº“ pollutants è¡¨ä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
                continue

            # ã€æ–°å¢ã€‘ç”Ÿæˆ distinct_id
            distinct_id = generate_distinct_id(date_val, hour_val, site_id, pollutant_id)

            # ã€ä¿®æ”¹ã€‘å°† distinct_id æ·»åŠ åˆ°è®°å½•ä¸­
            records_to_insert.append((distinct_id, site_id, pollutant_id, date_val, hour_val, value))

        # 4. æ‰¹é‡æ’å…¥æ•°æ®åº“
        if records_to_insert:
            insert_query = """
                -- ã€ä¿®æ”¹ã€‘åŒ…å« distinct_id å­—æ®µ
                INSERT INTO measurements (distinct_id, site_id, pollutant_id, date, hour, value)
                VALUES %s
                -- ç”±äº distinct_id æ˜¯ä¸»é”®ï¼Œå¦‚æœé‡å¤åˆ™ä¼šå†²çªï¼Œä½†è¿™é‡Œä½¿ç”¨ DO NOTHING ä¿æŒå¹‚ç­‰æ€§
                ON CONFLICT DO NOTHING
            """
            # ã€ä¿®æ”¹ã€‘execute_values æ¨¡æ¿éœ€è¦ 6 ä¸ªå‚æ•° (distinct_id, site_id, pollutant_id, date, hour, value)
            extras.execute_values(cursor, insert_query, records_to_insert, template="(%s, %s, %s, %s, %s, %s)")
            return len(records_to_insert)
        else:
            print("âš ï¸ è¯¥æ–‡ä»¶æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯æ’å…¥ã€‚")
            return 0

    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        # æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥ä¾¿ main å‡½æ•°å¯ä»¥æ•è·å¹¶è¿›è¡Œå›æ»š
        raise e


def main():
    conn = get_db_connection()
    if not conn:
        return

    try:
        cur = conn.cursor()

        # åŠ è½½ ID æ˜ å°„è¡¨
        site_map, pollutant_map = load_id_mappings(cur)
        print(f"â„¹ï¸ åŠ è½½äº† {len(site_map)} ä¸ªç«™ç‚¹å’Œ {len(pollutant_map)} ä¸ªæ±¡æŸ“ç‰©ç±»å‹ã€‚")

        # æŸ¥æ‰¾æ‰€æœ‰ CSV æ–‡ä»¶
        csv_files = glob.glob(os.path.join(CSV_FOLDER_PATH, "*.csv"))

        if not csv_files:
            print(f"âŒ åœ¨è·¯å¾„ '{CSV_FOLDER_PATH}' ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ã€‚")
            return

        total_inserted = 0

        for csv_file in csv_files:
            inserted_count = 0
            file_name = os.path.basename(csv_file)
            print(f"ğŸ” æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name}")

            try:
                # å°è¯•å¤„ç†æ–‡ä»¶
                inserted_count = process_csv_and_insert(csv_file, cur, site_map, pollutant_map)
                total_inserted += inserted_count

                # ã€å¢å¼ºäº‹åŠ¡ã€‘å•ä¸ªæ–‡ä»¶å¤„ç†æˆåŠŸåç«‹å³æäº¤
                conn.commit()
                print(f"âœ… æ–‡ä»¶ {file_name} å¤„ç†æˆåŠŸï¼Œæ’å…¥ {inserted_count} æ¡è®°å½•å¹¶å·²æäº¤ã€‚")

            except Exception as file_error:
                # ã€å¢å¼ºäº‹åŠ¡ã€‘å¦‚æœå•ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œå›æ»šå½“å‰æ–‡ä»¶çš„æ“ä½œ
                conn.rollback()
                print(f"âŒ æ–‡ä»¶ {file_name} å¤„ç†å¤±è´¥ï¼Œæ“ä½œå·²å›æ»šã€‚")
                print(f"âŒ è¯¦ç»†é”™è¯¯: {type(file_error).__name__}: {file_error}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶

        print(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼Œæ•°æ®åº“æ“ä½œç»“æŸã€‚æ€»è®¡æ’å…¥ {total_inserted} æ¡è®°å½•ã€‚")

    except Exception as e:
        # æ•è·è¿æ¥æˆ–åˆå§‹è®¾ç½®çš„é”™è¯¯
        if conn and 'cur' in locals():
            conn.rollback()
        print(f"âŒ å‘ç”Ÿä¸»ç¨‹åºé”™è¯¯æˆ–è¿æ¥é”™è¯¯ï¼Œå·²å›æ»šæ‰€æœ‰æœªæäº¤æ“ä½œã€‚")
        print(f"âŒ è¯¦ç»†é”™è¯¯: {type(e).__name__}: {e}")
    finally:
        if 'cur' in locals() and cur:
            cur.close()
        if conn:
            conn.close()


if __name__ == "__main__":
    main()